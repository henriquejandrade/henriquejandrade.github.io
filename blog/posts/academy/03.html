---
layout: blog
parent: ../..
title: üíª pix2pix
metatitle: pix2pix, cnn, cgan, gan, tradu√ß√£o de imagens
categories: blog, academy
description: "An√°lise do artigo Image-to-Image Translation with Conditional Adversarial Nets"
keywords: deep learning, pix2pix
date: 05/13/2020
---

<div id="main-div">
    <p class="title">
        <i>pix2pix</i>
    </p>

    <p>
        Oi gente, aqui inicio minha primeira postagem-an√°lise de um artigo. Escrevo sobre o *pix2pix*, um
        trabalho
        <a href="https://twitter.com/hashtag/pix2pix">abra√ßado pela comunidade art√≠stica experimental</a> por
        ser um gerador de
        imagens a partir de uma entrada visual (ou seja, uma imagem).
    </p>

    <!-- Image -->
    <img class="illustration" src="https://phillipi.github.io/pix2pix/images/edges2cats.jpg" />
    <p class="subtitle"></p>

    <p>
        A ferramenta tem seu m√©todo descrito no artigo <i>
            Image-to-Image Translation with Conditional Adversarial
            Nets
        </i>, um trabalho apresentado na confer√™ncia <i>Computer Vision and Pattern Recognition</i>, no Hava√≠ em
        2017.
    </p>

    <hr />

    <h2>
        A Ideia
    </h2>

    <p>
        A ideia dos autores do sistema √© a concep√ß√£o de uma ferramenta para tradu√ß√£o entre imagens. Eles apontam
        que
        j√° existem sistemas para essa finalidade, mas que s√£o modelos diferentes para cara um desses fins.
        Portanto,
        o trabalho conv√©m uma <b>rede de gera√ß√£o advers√°ria condicional</b> (cGAN), adapt√°vel a diferentes
        problemas
        "imagem-para-imagem".
    </p>

    <!-- Image -->
    <img class="illustration" src="https://phillipi.github.io/pix2pix/images/teaser_v3.jpg" />
    <p class="subtitle"></p>

    <hr />

    <h2>
        Rede de Gera√ß√£o Advers√°ria (GAN)
    </h2>

    <p>
        Na sua proposi√ß√£o cl√°ssica, a GAN reproduz uma disputa entre duas redes, a rede <b>geradora</b> <span
            class="code">G</span> e a <b>discriminadora</b> <span class="code">D</span>, a que vai verificar a
        sa√≠da da primeira rede. As regras gerais da disputa s√£o:
    </p>
    <ul>
        <li>
            A rede geradora recebe como entrada um vetor de ru√≠do <span class="code">z</span> e tem como sa√≠da
            uma imagem <span class="code">y</span>;
        </li>

        <li>
            A rede discriminadora, a que julga, recebe como entrada uma imagem <span class="code">x</span> e a
            imagem <span class="code">y</span>, sa√≠da da rede geradora;
        </li>

        <li>
            A rede discriminadora determina se a sa√≠da de <span class="code">y</span> √© parte do
            <i>groundtruth</i> com <span class="code">x</span>, ou seja, se <span class="code">y</span> √©
            uma imagem real ou se ela √© falsa;
        </li>

        <li>
            O objetivo de <span class="code">D</span> √© minimizar seu erro, enquanto o objetivo de <span
                class="code">G</span> √© maximizar o erro de <span class="code">D</span>.
        </li>
    </ul>

    <p>
        Dessa forma, idealmente, evoluimos duas redes, uma especialista em discernir se uma imagem foi gerada
        artificialmente a partir do vetor <span class="code">z</span> e uma rede especialista em gerar imagens
        que enganam a primeira rede.
        Estendendo a defini√ß√£o a seu limite, teremos uma rede <span class="code">G</span> que gera imagens t√£o
        convincentes que a rede <span class="code">D</span>
        sempre retornar√° <span class="code">0.5</span>, que se interpretaria como "pode ser real ou n√£o".
    </p>

    <h2>
        cGAN, sua vers√£o condicional
    </h2>

    <p>
        Uma adapta√ß√£o da rede de gera√ß√£o advers√°ria leva em considera√ß√£o uma imagem <span class="code">x</span>
        como entrada da rede geradora <span class="code">G</span>. Dessa forma, concebe-se uma rede que realiza
        uma opera√ß√£o de imagem para imagem. Assim como a
        GAN, a rede <span class="code">G</span> tenta diminuir o objetivo de <span class="code">D</span> e,
        por sua vez, <span class="code">D</span> tenta aumentar seu pr√≥prio objetivo.
    </p>

    <p>
        S√£o as regras da cGAN:
    </p>

    <ol>
        <li><span class="code">G</span> recebe uma imagem <span class="code">x</span> e um vetor de ru√≠do <span
                class="code">z</span> como entradas;</li>

        <li><span class="code">D</span>, por sua vez, recebe uma imagem <span class="code">x</span> e a sa√≠da de
            <span class="code">G</span>;</li>

        <li>A fun√ß√£o <i>loss</i> calcula o inverso desse objetivo, na tentativa de minimiz√°-lo;</li>

        <li><span class="code">D</span> avalia seu resultado tendo como entradas as imagens <span class="code">x</span>
            e <span class="code">y</span>;</li>
    </ol>

    <p>
        Para isso, temos que <i>loss</i> de cGAN √©:
    </p>

    <p class="code-block">
        LcGAN = Ex,y[log D(x, y)] + Ex,y[log (1 - D(x, G(x, z)))]
    </p>

    <p>Para for√ßar as sa√≠das do gerador a resultados mais pr√≥ximos do <i>ground truth</i>, o autor sugere
        acrescentar uma outra fun√ß√£o objetivo <span class="code">L1</span>, que em compara√ß√£o com <span
            class="code">L2</span> gera menos <i>blur</i>:</p>

    <p class="code-block">
        LL1 = Ex,y,z[|y - G(x, z)|]
    </p>

    <p>Portanto, a fun√ß√£o objetivo final se torna:</p>

    <p class="code-block">
        G* = arg min max LcGAN(G, D) + Œª LL1(G)
    </p>

    <hr />

    <h2>As arquiteturas em disputa</h2>

    <p>Para a rede geradora, o autor adota uma arquitetura <b>U-Net</b> e para a rede discriminadora, uma
        arquitetura PatchGAN.</p>

    <!-- Image -->
    <img class="illustration" src="images/03/unet.png" />
    <p class="subtitle">U-Net √© uma arquitetura <i>encoder-decoder</i> com conex√µes que passam direto entre
        camadas.</p>

    <h2>Resultados</h2>

    <!-- Image -->
    <img class="illustration" src="images/03/results.jpg" />
    <p class="subtitle">O uso de diferentes fun√ß√µes objetivo levam a qualidades diferentes de imagens</p>

    <!-- Image -->
    <img class="illustration" src="images/03/table1.png" />
    <p class="subtitle">FCN-scores para fun√ß√µes objetivos diferentes sobre o <i>dataset</i> Cityscapes</p>

    <!-- Image -->
    <img class="illustration" src="images/03/table3.png" />
    <p class="subtitle">FCN-scores para <i>patches</i> de tamanhos diferentes do discriminador</p>

    <blockquote>
        O "FCN-score" baseia-se em uma terceira rede, utilizada para reconhecimento por outros trabalhos como
        <i>benchmark</i> para os resultados gerados pela cGAN.
    </blockquote>
</div>